**Lernergebnisse:**  
Die Studierenden lernen Techniken und Anwendungen der Datenanalyse auf Basis des Hadoop-Ökosystems kennen und verstehen deren Funktion. Mit dem vermittelten Wissen sind die Studierenden in der Lage die für einen konkreten Anwendungsfall geeigneten Techniken auszuwählen und anzuwenden. Dabei kennen Sie die Vor- und Nachteile verschiedener Verfahren und Werkzeuge und können deren Anwendbarkeit bei einer konkreten Problemstellung gegeneinander abwägen und das am besten passende Verfahren einsetzen.

**Inhaltsbeschreibung:**  
Die Vorlesung betrachtet nach einer Übersicht über das Hadoop Ökosystem und dessen Architektur sowie den grundlegenden Funktion von Hadoop einzelnen Komponenten (HDFS, HBase, Hive, Pig, MapReduce, Spark, Storm, …) von Hadoop zur Datenanalyse im Detail. Insbesondere geht es hier um die Programmierung einer Datenanalyselösung unter Nutzung der verschiedenen Werkzeuge. Anhand von Beispielen werden diese Komponenten zur Anwendung gebracht und deren Spezifika miteinander verglichen.
Die Vorlesung ordnet die Komponenten einem Vorgehensmodell mittels eines Standardprozess zu. Beispiele aus dem industriellen Umfeld stellen die konkrete Anwendung von Hadoop in der Praxis dar. Bei den Vorlesungen mit Industriebeteiligung herrscht Anwesenheitspflicht.

Im Praktikum setzen die Studierenden die in der Vorlesung vorgestellten Werkzeuge ein.

**Eingangsvoraussetzungen:**  
* Grundlegende Kenntnisse in Python bzw. einer höheren Programmiersprache
* Grundlagen der Statistik
* Datenstrukturen
* Grundlagen der Rechnerarchitektur